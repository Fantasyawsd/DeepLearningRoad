# 机器学习理论与实战 (Machine Learning Theory and Practice)

本文档包含传统机器学习算法的理论原理和实战应用。

## 机器学习概述

* [机器学习原理](https://github.com/shunliz/Machine-Learning):star:
* [ID3、C4.5、CART、随机森林、bagging、boosting、Adaboost、GBDT、xgboost算法总结](https://zhuanlan.zhihu.com/p/34534004)
* [数据挖掘十大算法简要说明](http://www.cnblogs.com/en-heng/p/5013995.html)，[机器学习十大经典算法入门](https://blog.csdn.net/qq_42379006/article/details/80741808) && [【算法模型】轻松看懂机器学习十大常用算法](https://www.cnblogs.com/ljt1412451704/p/9678248.html)

## 信息论基础

### 信息论
* [机器学习中的各种熵](https://zhuanlan.zhihu.com/p/35423404)    
* [从香农熵到手推KL散度：纵览机器学习中的信息论](https://zhuanlan.zhihu.com/p/32985487)

## 经典机器学习算法

### 多层感知机(MLP)
* [多层感知机（MLP）学习与总结博客](https://blog.csdn.net/baidu_33718858/article/details/84972537)
* [多层感知机：Multi-Layer Perceptron](https://blog.csdn.net/xholes/article/details/78461164)
* [神经网络基础-多层感知器(MLP)](https://blog.csdn.net/weixin_38206214/article/details/81137911)

### k近邻(KNN)
* [机器学习之KNN（k近邻）算法详解](https://blog.csdn.net/sinat_30353259/article/details/80901746)

### k均值(K-means)
* [Kmeans聚类算法详解](https://blog.csdn.net/qq_32892383/article/details/80107795)

### 朴素贝叶斯(Naive Bayesian)
* [一个例子搞清楚（先验分布/后验分布/似然估计）](https://blog.csdn.net/qq_23947237/article/details/78265026)
* [朴素贝叶斯分类器（Naive Bayesian Classifier）](https://blog.csdn.net/qq_32690999/article/details/78737393)
* [朴素贝叶斯分类器 详细解析](https://blog.csdn.net/qq_17073497/article/details/81076250)

### 决策树(Decision Tree)
* [最常见核心的决策树算法详细介绍，含ID3、C4.5、CART:star:](https://mp.weixin.qq.com/s/lXaPZyNrgG9LBv-JHdGm9A) && [最常用的决策树算法！Random Forest、Adaboost、GBDT 算法:star:](https://mp.weixin.qq.com/s/Nl_-PdF0nHBq8yGp6AdI-Q) && [终于有人把XGBoost 和 LightGBM 讲明白了，项目中最主流的集成算法！:star:](https://mp.weixin.qq.com/s/LoX987dypDg8jbeTJMpEPQ)
* [为什么xgboost要用泰勒展开，优势在哪里](http://blog.itblood.com/4082.html)
* [Python3《机器学习实战》学习笔记（二）：决策树基础篇之让我们从相亲说起](https://blog.csdn.net/c406495762/article/details/75663451)
* [Python3《机器学习实战》学习笔记（三）：决策树实战篇之为自己配个隐形眼镜](https://blog.csdn.net/c406495762/article/details/76262487)
* [机器学习实战教程（十三）：树回归基础篇之CART算法与树剪枝](http://cuijiahua.com/blog/2017/12/ml_13_regtree_1.html)
* [《机器学习实战》基于信息论的三种决策树算法(ID3,C4.5,CART)](https://blog.csdn.net/gamer_gyt/article/details/51242815)
* [说说决策树剪枝算法](https://zhuanlan.zhihu.com/p/31404571)
* [机器学习实战 第九章 树回归](https://blog.csdn.net/namelessml/article/details/52595066)
* [决策树值ID3、C4.5实现](https://blog.csdn.net/u014688145/article/details/53212112)
* [决策树之CART实现](https://blog.csdn.net/u014688145/article/details/53326910)

### 随机森林(Random Forest)
* [随机森林和GBDT的区别](https://blog.csdn.net/login_sonata/article/details/73929426)
* [随机森林（Random Forest）入门与实战](https://blog.csdn.net/sb19931201/article/details/52601058)
* [随机森林之特征选择](https://www.cnblogs.com/justcxtoworld/p/3447231.html)

### 线性回归（Linear Regression）
* [线性回归最小二乘法和最大似然估计](https://blog.csdn.net/lt793843439/article/details/91392646)
* [【从入门到放弃】线性回归](https://zhuanlan.zhihu.com/p/147297924)
* [线性回归(频率学派-最大似然估计)与岭回归(贝叶斯角度-最大后验估计)的概率解释](https://blog.csdn.net/z_feng12489/article/details/101388745)
* [机器学习笔记四：线性回归回顾与logistic回归](https://blog.csdn.net/xierhacker/article/details/53316138)

### 逻辑回归(Logistic Regression)
* [【机器学习面试总结】—— LR（逻辑回归）](https://zhuanlan.zhihu.com/p/100763009)
* [【机器学习面试题】逻辑回归篇](https://zhuanlan.zhihu.com/p/62653034)
* [极大似然概率和最小损失函数，以及正则化简介](https://www.jianshu.com/p/9d2686cd407e)
* [GLM(广义线性模型) 与 LR(逻辑回归) 详解](https://blog.csdn.net/Cdd2xd/article/details/75635688)

### 支持向量机(SVM) 
* [【机器学习面试总结】—— SVM](https://zhuanlan.zhihu.com/p/93715996)
* [SVM系列-从基础到掌握](https://zhuanlan.zhihu.com/p/61123737)
* [SVM通俗导论 July](https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E9%80%9A%E4%BF%97%E5%AF%BC%E8%AE%BA%EF%BC%88%E7%90%86%E8%A7%A3SVM%E7%9A%84%E4%B8%89%E5%B1%82%E5%A2%83%E7%95%8C%EF%BC%89LaTeX%E6%9C%80%E6%96%B0%E7%89%88_2015.1.9.pdf) 
* [核函数 ](): [机器学习有很多关于核函数的说法，核函数的定义和作用是什么？](https://www.zhihu.com/question/24627666) && [SVM中，高斯核为什么会把原始维度映射到无穷多维？](https://www.zhihu.com/question/35602879) && [svm核函数的理解和选择](https://blog.csdn.net/leonis_v/article/details/50688766) && [核函数和径向基核函数 (Radial Basis Function)--RBF](https://blog.csdn.net/huang1024rui/article/details/51510611) && [SVM核函数](https://blog.csdn.net/xiaowei_cqu/article/details/35993729)

### 提升方法(Adaboost)
* [当我们在谈论GBDT：从 AdaBoost 到 Gradient Boosting](https://zhuanlan.zhihu.com/p/25096501)
* [AdaBoost到GBDT系列]()
  * [当我们在谈论GBDT：从 AdaBoost 到 Gradient Boosting](https://zhuanlan.zhihu.com/p/25096501?refer=data-miner)
  * [当我们在谈论GBDT：Gradient Boosting 用于分类与回归](https://zhuanlan.zhihu.com/p/25257856?refer=data-miner)
  * [当我们在谈论GBDT：其他 Ensemble Learning 算法](https://zhuanlan.zhihu.com/p/25443980)

### 梯度提升决策树(GBDT)
* [LightGBM大战XGBoost](https://zhuanlan.zhihu.com/p/35645973)
* [概述XGBoost、Light GBM和CatBoost的同与不同](https://zhuanlan.zhihu.com/p/34698733)    && [XGBoost、LightGBM、Catboost总结](https://www.cnblogs.com/lvdongjie/p/11391245.html) && [XGBoost、Light GBM和CatBoost的参数及性能比较](https://zhuanlan.zhihu.com/p/34698733)
* [梯度提升决策树](https://zhuanlan.zhihu.com/p/36339161)
* [GBDT原理及应用](https://zhuanlan.zhihu.com/p/30339807)
* [XGBOOST原理篇](https://zhuanlan.zhihu.com/p/31654000)
* [xgboost入门与实战（原理篇）](https://blog.csdn.net/sb19931201/article/details/52557382) && [xgboost入门与实战（实战调参篇）](https://blog.csdn.net/sb19931201/article/details/52577592)
* [【干货合集】通俗理解kaggle比赛大杀器xgboost](https://zhuanlan.zhihu.com/p/41417638)
* [GBDT分类的原理及Python实现](https://blog.csdn.net/bf02jgtrs00xktcx/article/details/82719765)
* [GBDT原理及利用GBDT构造新的特征-Python实现](https://blog.csdn.net/shine19930820/article/details/71713680)
* [Python+GBDT算法实战——预测实现100%准确率](https://www.jianshu.com/p/47e73a985ba1)
* [xgboost之近似分位数算法（直方图算法）详解](https://blog.csdn.net/m0_37870649/article/details/104561431)

### EM(期望最大化)			
* [人人都懂的EM算法 ](https://zhuanlan.zhihu.com/p/36331115)
* [EM算法入门文章](https://zhuanlan.zhihu.com/p/61768577)                      

### 高斯混合模型(GMM)
* [高斯混合模型与EM算法的数学原理及应用实例](https://zhuanlan.zhihu.com/p/67107370)
* [高斯混合模型（GMM）](https://zhuanlan.zhihu.com/p/30483076)

### 马尔科夫决策过程(MDP)		
* [马尔科夫决策过程之Markov Processes（马尔科夫过程）](https://zhuanlan.zhihu.com/p/35124726)
* [马尔科夫决策过程之Markov Reward Process（马尔科夫奖励过程）](https://zhuanlan.zhihu.com/p/35231424)
* [马尔科夫决策过程之Bellman Equation（贝尔曼方程）](https://zhuanlan.zhihu.com/p/35261164)
* [马尔科夫决策过程之Markov Decision Process(马尔科夫决策过程)](https://zhuanlan.zhihu.com/p/35354956)
* [马尔科夫决策过程之最优价值函数与最优策略](https://zhuanlan.zhihu.com/p/35373905)

### 条件随机场(CRF, 判别式模型)
* [如何轻松愉快地理解条件随机场](https://zhuanlan.zhihu.com/p/104562658)
* [如何用简单易懂的例子解释条件随机场（CRF）模型？它和HMM有什么区别？](https://www.zhihu.com/question/35866596)
* [HMM ,MHMM,CRF 优缺点与区别](https://blog.csdn.net/u013378306/article/details/55213029)

## 降维算法

### 降维算法概述
* [数据降维算法-从PCA到LargeVis](https://zhuanlan.zhihu.com/p/62470700)
* [12种降维方法终极指南（含Python代码）](https://zhuanlan.zhihu.com/p/43225794)

### 主成分分析(PCA)
* [主成分分析（PCA）原理详解](https://blog.csdn.net/program_developer/article/details/80632779)
* [图文并茂的PCA教程](https://blog.csdn.net/hustqb/article/details/78394058)
* [PCA数学原理](http://www.360doc.com/content/13/1124/02/9482_331688889.shtml)

### 奇异值分解(SVD)
* [强大的矩阵奇异值分解(SVD)及其应用](https://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html)
* [奇异值分解（SVD）](https://zhuanlan.zhihu.com/p/29846048)
* [奇异值分解(SVD)原理详解及推导](https://blog.csdn.net/zhongkejingwang/article/details/43053513)    
* [SVD在推荐系统中的应用详解以及算法推导](https://blog.csdn.net/zhongkejingwang/article/details/43083603)

### 线性判别分析(LDA)
* [教科书上的LDA为什么长这个样子？](https://zhuanlan.zhihu.com/p/42238953)

### t分布随机邻居嵌入(TSNE)
* [流形学习-高维数据的降维与可视化](https://blog.csdn.net/u012162613/article/details/45920827)
* [tSNE](https://blog.csdn.net/flyingzhan/article/details/79521765)
* [使用t-SNE可视化图像embedding](https://zhuanlan.zhihu.com/p/81400277)

## 聚类算法

### 谱聚类(Spectral Clustering)
* [谱聚类（Spectral Clustering）算法介绍](https://blog.csdn.net/qq_24519677/article/details/82291867)
* [聚类5--谱和谱聚类](https://blog.csdn.net/xueyingxue001/article/details/51966980)

## 其他算法

### 标签传播算法(Label Propagation Algorithm)    
* [标签传播算法（Label Propagation）及Python实现](https://blog.csdn.net/zouxy09/article/details/49105265)
    * [参考资料](https://github.com/Mikoto10032/DeepLearning/blob/master/books/Semi-Supervised%20Learning%20with%20Graphs.pdf)

### 蒙塔卡罗树搜索(MCTS)
* [蒙特卡洛树搜索入门指南](https://zhuanlan.zhihu.com/p/34950988)

### 集成(Ensemble)
* [集成学习之bagging,stacking,boosting概念理解](https://zhuanlan.zhihu.com/p/41809927) && [Bagging和Boosting的总结](https://www.zhihu.com/follow)
* [集成学习法之bagging方法和boosting方法](https://blog.csdn.net/qq_30189255/article/details/51532442)
* [Bagging,Boosting,Stacking](https://blog.csdn.net/Mr_tyting/article/details/72957853) && [常用的模型集成方法介绍：bagging、boosting 、stacking](https://zhuanlan.zhihu.com/p/65888174)

### 异常点检测
* [数据挖掘中常见的「异常检测」算法有哪些？](https://www.zhihu.com/question/280696035/answer/417091151)
* [异常点检测算法综述](https://zhuanlan.zhihu.com/p/30169110)
* [异常检测的N种方法，其中有一个你一定想不到](https://mp.weixin.qq.com/s/RYLlUJiYbWqGIhzflbRGEg)
* [异常检测资源汇总：anomaly-detection-resources](https://zhuanlan.zhihu.com/p/158349346)

## 机器学习实战

### 特征工程
* [机器学习中，有哪些特征选择的工程方法？](https://www.zhihu.com/question/28641663) && [机器学习（四）：数据预处理--特征工程概述](https://zhuanlan.zhihu.com/p/103070096) && [特征工程完全手册 - 从预处理、构造、选择、降维、不平衡处理，到放弃](https://zhuanlan.zhihu.com/p/94994902) && [特征工程中的「归一化」有什么作用](https://www.zhihu.com/question/20455227)

### sklearn实战
* [15分钟带你入门sklearn与机器学习——分类算法篇](https://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247484110&idx=1&sn=b016e270d7b7707e6ad41a81ca45fc28&chksm=c0791fd7f70e96c103a8a2aebee166ce14f5648b3b889dd85dd9786f48b6b8269f11e5e27e1c&scene=21#wechat_redirect) && [如何为你的回归问题选择最合适的机器学习方法？](https://zhuanlan.zhihu.com/p/62034592)
* [十分钟上手sklearn：安装，获取数据，数据预处理](https://zhuanlan.zhihu.com/p/105039597) && [十分钟上手sklearn：特征提取，常用模型，交叉验证](https://zhuanlan.zhihu.com/p/105041301)

### 实战项目
* [MachineLearning_Python](https://github.com/lawlite19/MachineLearning_Python)
* [Machine Learning Course with Python](https://github.com/machinelearningmindset/machine-learning-course)
* [Statistical-Learning-Method_Code](https://github.com/Dod-o/Statistical-Learning-Method_Code)
* [Python3机器学习](https://blog.csdn.net/c406495762/column/info/16415)

### 模型调参
* [含大牛总结的分类模型一般需要调节的参数](https://www.jianshu.com/p/9d2452fc93c2)